{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e475919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, logging\n",
    "from datetime import datetime\n",
    "\n",
    "import mlflow\n",
    "import mlflow.artifacts as artifacts\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "\n",
    "from flame import CAREInferenceSession\n",
    "from flame.utils import get_input_and_GT_paths\n",
    "import flame.eval as eval\n",
    "from flame.error import (\n",
    "    FLAMEImageError, \n",
    "    CAREInferenceError, \n",
    "    CAREDatasetError, \n",
    "    FLAMEEvalError\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ab5827",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:5050\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1eb6bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"20250618_224I_denoising_5to40F\"\n",
    "DATASET_DIREC = os.path.join(\"/mnt/d/data/processed\", DATASET_NAME)\n",
    "TEST_DIREC = os.path.join(DATASET_DIREC, \"test\")\n",
    "METRICS = [\n",
    "    \"mse\",\n",
    "    \"mae\",\n",
    "    \"ssim\"\n",
    "]\n",
    "CONFIG_JSON_PATH = os.path.join(DATASET_DIREC, \"patch_config.json\")\n",
    "MLFLOW_RUN_ID = \"bf9a43f3ec154c9ba2deb6de2fb0db33\"\n",
    "TEMP_DIREC = os.path.join(os.getcwd(), \"temp\")\n",
    "ONNX_RELATIVE_PATH = os.path.join(\"model\")\n",
    "JSON_RELATIVE_PATH = os.path.join(\"model_config\", \"model_config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2f28ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(\"main\")\n",
    "logging.basicConfig(\n",
    "    filename=os.path.join(os.getcwd(), \"logs\", f\"{datetime.now().strftime('%Y%m%d-%H%M%S')}_logger.log\"),\n",
    "    encoding=\"utf-8\",\n",
    "    level=logging.DEBUG\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f5ac18",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(TEMP_DIREC, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89215a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.isdir(TEST_DIREC), f\"Could not find test set directory at path {TEST_DIREC}\"\n",
    "assert os.path.isdir(TEMP_DIREC), f\"Could not find temp directory. Look at path {TEMP_DIREC}\"\n",
    "assert os.path.isfile(CONFIG_JSON_PATH), f\"Could not find config json at path {CONFIG_JSON_PATH}\"\n",
    "for metric in METRICS:\n",
    "    try:\n",
    "        getattr(eval, metric)\n",
    "    except AttributeError as e:\n",
    "        logger.error(f\"Could not find {metric} among available evaluation metrics.\")\n",
    "        raise FLAMEEvalError(f\"Could not find {metric} among available evaluation metrics.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120924ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = json.load(open(CONFIG_JSON_PATH, \"r\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cd75d2",
   "metadata": {},
   "source": [
    "### Getting MLFlow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6add5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    artifacts.download_artifacts(\n",
    "        run_id=MLFLOW_RUN_ID,\n",
    "        artifact_path=ONNX_RELATIVE_PATH,\n",
    "        dst_path=TEMP_DIREC\n",
    "    )\n",
    "except Exception as e:\n",
    "    logger.error(f\"Could not load model.onnx from mlflow run of id {MLFLOW_RUN_ID}.\\nEXCEPTION: {e}\")\n",
    "    raise CAREInferenceError(f\"Could not load model.onnx from mlflow run of id {MLFLOW_RUN_ID}.\\nEXCEPTION: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1519606d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    artifacts.download_artifacts(\n",
    "        run_id=MLFLOW_RUN_ID,\n",
    "        artifact_path=JSON_RELATIVE_PATH,\n",
    "        dst_path=TEMP_DIREC\n",
    "    )\n",
    "except Exception as e:\n",
    "    logger.error(f\"Could not load model_config.json from mlflow run of id {MLFLOW_RUN_ID}.\\nEXCEPTION: {e}\")\n",
    "    raise CAREInferenceError(f\"Could not load model_config.json from mlflow run of id {MLFLOW_RUN_ID}.\\nEXCEPTION: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dc8921",
   "metadata": {},
   "outputs": [],
   "source": [
    "ONNX_PATH = os.path.join(TEMP_DIREC, \"model\", \"model.onnx\")\n",
    "MODEL_CONFIG_PATH = os.path.join(TEMP_DIREC, \"model_config\", \"model_config.json\")\n",
    "assert os.path.isfile(ONNX_PATH), f\"Could not find model ONNX at {ONNX_PATH}\"\n",
    "assert os.path.isfile(MODEL_CONFIG_PATH), f\"Could not find model config JSON at {MODEL_CONFIG_PATH}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b92d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = CAREInferenceSession(\n",
    "    model_path=ONNX_PATH,\n",
    "    model_config_path=MODEL_CONFIG_PATH,\n",
    "    dataset_config_path=MODEL_CONFIG_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7f6b2e",
   "metadata": {},
   "source": [
    "### Starting Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f610859a",
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAMES_LOW = config['FLAME_Dataset']['input']['n_frames']\n",
    "FRAMES_GT = config['FLAME_Dataset']['output']['n_frames']\n",
    "low_paths, GT_paths = get_input_and_GT_paths(\n",
    "    input_direc=TEST_DIREC,\n",
    "    input_frames=FRAMES_LOW,\n",
    "    gt_frames=FRAMES_GT,\n",
    "    logger=logger\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a99703",
   "metadata": {},
   "outputs": [],
   "source": [
    "for low_path, gt_path in tqdm(\n",
    "        iterable=zip(low_paths, GT_paths),\n",
    "        total=len(low_paths),\n",
    "        ascii=True\n",
    "    ):\n",
    "    try:\n",
    "        low=tiff.imread(low_path).transpose(0,2,3,1).astype(np.float32)\n",
    "        gt=tiff.imread(gt_path).transpose(0,2,3,1).astype(np.float32)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Could not load input and/or GT images from {os.path.basename(low_path)} & {os.path.basename(gt_path)}\")\n",
    "        continue\n",
    "    \n",
    "    assert low.shape == gt.shape, f\"Input and GT image shapes do not match (found {low.shape} and {gt.shape})\"\n",
    "\n",
    "    pred = engine.predict(low)\n",
    "\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1a8f54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "care",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
