{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e475919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, logging\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "\n",
    "import mlflow\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from flame import CAREInferenceSession, FLAMEImage\n",
    "from flame.utils import _compress_dict_fields\n",
    "from flame.io import find_dataset_config, flame_paths_from_ids\n",
    "import flame.eval as eval\n",
    "from flame.error import FLAMEEvalError, CAREInferenceError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1eb6bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAMEImage_ROOT_DIR = \"/mnt/d/data/raw\"\n",
    "DATASET_JSON_DIREC = os.path.join(os.getcwd(), \"datasets\")\n",
    "FLAMEImage_INDEX_PATH = os.path.join(DATASET_JSON_DIREC, \"raw_image_index.csv\")\n",
    "DATASET_ID = \"0x0003\"\n",
    "METRICS = [\n",
    "    \"mse\",\n",
    "    \"mae\",\n",
    "    \"ssim\"\n",
    "]\n",
    "FRAMES_LOW = 5\n",
    "FRAMES_GT = 40\n",
    "TRACKING_URI = \"http://127.0.0.1:5050\"\n",
    "MLFLOW_RUN_IDS = [\n",
    "    \"f6f35ad93a6a4c2b9a1a99ac7dea4094\",\n",
    "    \"bf9a43f3ec154c9ba2deb6de2fb0db33\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd2f28ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(\"MAIN\")\n",
    "logging.basicConfig(\n",
    "    filename=os.path.join(os.getcwd(), \"logs\", f\"{datetime.now().strftime('%Y%m%d-%H%M%S')}_logger.log\"),\n",
    "    encoding=\"utf-8\",\n",
    "    level=logging.DEBUG\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9fad60",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.isdir(FLAMEImage_ROOT_DIR), f\"Could not find FLAMEImage root directory at {FLAMEImage_ROOT_DIR}\"\n",
    "assert os.path.isdir(DATASET_JSON_DIREC), f\"Could not find the dataset directory at {DATASET_JSON_DIREC}\"\n",
    "assert os.path.isfile(FLAMEImage_INDEX_PATH), f\"Could not find FLAMEImage index at {FLAMEImage_INDEX_PATH}\"\n",
    "for metric in METRICS:\n",
    "    try:\n",
    "        getattr(eval, metric)\n",
    "    except AttributeError as e:\n",
    "        logger.error(f\"Could not find {metric} among available evaluation metrics.\")\n",
    "        raise FLAMEEvalError(f\"Could not find {metric} among available evaluation metrics.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7c0aced",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path, config = find_dataset_config(\n",
    "    input_direc=DATASET_JSON_DIREC,\n",
    "    this_id=DATASET_ID,\n",
    ")\n",
    "test_ids = config['FLAME_Dataset']['test_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63359adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = flame_paths_from_ids(\n",
    "    root_dir=FLAMEImage_ROOT_DIR,\n",
    "    index_path=FLAMEImage_INDEX_PATH,\n",
    "    id_list=test_ids\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48ba6d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"Found {len(paths)} FLAME Images from {DATASET_ID} test set in {FLAMEImage_ROOT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daa4710",
   "metadata": {},
   "source": [
    "### Loading FLAMEImages into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e4bff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|########6 | 19/22 [00:52<00:04,  1.66s/it]"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "logger.info(f\"Loading FLAMEImages into memory...\")\n",
    "for p in tqdm(paths, total=len(paths), ascii=True):\n",
    "    im = FLAMEImage(\n",
    "        impath=p,\n",
    "        jsonext='tileData.txt'\n",
    "    )\n",
    "    images.append(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cd75d2",
   "metadata": {},
   "source": [
    "### Getting MLFlow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50ab5827",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(uri=TRACKING_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4c66f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating run 1 / 2...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "352e0cdcc4de40bc939c86626d797540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "230582f3649f498daa11dc40f7d5fb6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating run 2 / 2...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "059b438c07f94a92b9cf7a74e1afdef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "941948619543460593ba3c37818d434b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inference_engines = []\n",
    "for rdx, RUN_ID in enumerate(MLFLOW_RUN_IDS):\n",
    "    logger.info(f\"Evaluating run {rdx+1} / {len(MLFLOW_RUN_IDS)}...\")\n",
    "    print(f\"Evaluating run {rdx+1} / {len(MLFLOW_RUN_IDS)}...\")\n",
    "\n",
    "    try:\n",
    "        engine = CAREInferenceSession.from_mlflow_uri(\n",
    "            tracking_uri=TRACKING_URI,\n",
    "            run_id=RUN_ID,\n",
    "        )\n",
    "        inference_engines.append(engine)\n",
    "    except Exception as e:\n",
    "        logger.exception(f\"Could not initialize CAREInferenceSession from MLFlow run id {RUN_ID}.\\n{e.__class__.__name__}: {e}\")\n",
    "        raise CAREInferenceError(f\"Could not initialize CAREInferenceSession from MLFlow run id {RUN_ID}.\\n{e.__class__.__name__}: {e}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7f6b2e",
   "metadata": {},
   "source": [
    "### Starting Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a99703",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_metrics = {x: [] for x in METRICS}\n",
    "eval_metrics = {x: [] for x in METRICS}\n",
    "\n",
    "for low_path, gt_path in tqdm(\n",
    "        iterable=zip(low_paths, GT_paths),\n",
    "        total=len(low_paths),\n",
    "        ascii=True\n",
    "    ):\n",
    "    try:\n",
    "        t1 = time()\n",
    "        low=tiff.imread(low_path).transpose(0,2,3,1).astype(np.float32)\n",
    "        gt=tiff.imread(gt_path).transpose(0,2,3,1).astype(np.float32)\n",
    "        t2 = time()\n",
    "        logger.info(f\"Loaded 2 images, taking {t2 - t1:.2f}s.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Could not load input and/or GT images from {os.path.basename(low_path)} & {os.path.basename(gt_path)}\")\n",
    "        continue\n",
    "    \n",
    "    assert low.shape == gt.shape, f\"Input and GT image shapes do not match (found {low.shape} and {gt.shape})\"\n",
    "\n",
    "    pred = engine.predict(low).astype(np.float32)\n",
    "\n",
    "    for metric in METRICS:\n",
    "        input_metrics[metric].append(getattr(eval, metric)(low[0,...], gt[0,...]))\n",
    "        eval_metrics[metric].append(getattr(eval, metric)(pred[0,...], gt[0,...]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef913c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=input_metrics)\n",
    "df[\"source\"] = [\"input vs. gt\"] * len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c90457",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pd.DataFrame(data=eval_metrics)\n",
    "eval_df[\"source\"] = [\"pred vs. gt\"] * len(eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d95caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.concat([df, eval_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc31261",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_id=MLFLOW_RUN_ID):\n",
    "    mlflow.log_params(_compress_dict_fields(config))\n",
    "    for metric in METRICS:\n",
    "        sns.catplot(data=all_df, x=\"source\", y=metric)\n",
    "        mlflow.log_metric(f\"ds{DATASET_ID}_test_{metric}\", np.mean(eval_df[metric]))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "care",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
