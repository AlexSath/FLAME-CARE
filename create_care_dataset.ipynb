{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff7c999",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import json\n",
    "import gc\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import tifffile as tiff\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm, tqdm_notebook\n",
    "\n",
    "from flame import FLAMEImage\n",
    "from flame.error import FLAMEImageError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc0ae51",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIREC = \"/mnt/d/data/raw\"\n",
    "OUTPUT_DIREC = \"/mnt/d/data/processed\"\n",
    "DATASET_DIREC = os.path.join(os.getcwd(), \"datasets\")\n",
    "DS_TYPE = \"denoising\"\n",
    "INPUT_N_FRAMES = 5\n",
    "OUTPUT_N_FRAMES = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c0daf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(\"main\")\n",
    "logging.basicConfig(\n",
    "    filename=f\"{datetime.now().strftime('%Y%m%d-%H%M%S')}_logger.log\",\n",
    "    encoding=\"utf-8\",\n",
    "    level=logging.DEBUG\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb1543c",
   "metadata": {},
   "source": [
    "### Find images to be used in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58f5829",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_INDEX_PATH = os.path.join(DATASET_DIREC, \"raw_image_index.csv\")\n",
    "assert os.path.isfile(IMAGE_INDEX_PATH), f\"Image index not found at {IMAGE_INDEX_PATH}\"\n",
    "IMAGE_INDEX = pd.read_csv(IMAGE_INDEX_PATH)\n",
    "IMAGE_INDEX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f4e490",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREINDEXED_IMAGES = IMAGE_INDEX['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af657550",
   "metadata": {},
   "outputs": [],
   "source": [
    "this_ds = {}\n",
    "for idx, relpath in tqdm(\n",
    "        zip(IMAGE_INDEX['id'], IMAGE_INDEX['image']),\n",
    "        ascii=True,\n",
    "        unit=\"image\",\n",
    "        total=len(IMAGE_INDEX)\n",
    "    ):\n",
    "    this_impath = os.path.join(INPUT_DIREC, relpath)\n",
    "    if os.path.isfile(this_impath):\n",
    "        logger.info(f\"Found image of id {idx} at {this_impath}\")\n",
    "        try:\n",
    "            this_image = FLAMEImage(this_impath, \"tileData.txt\")\n",
    "        except FLAMEImageError as e: # skipping those that could not be initialized for any reasonj\n",
    "            logger.error(f\"Could not initialize image of id {idx} at {this_impath}\")\n",
    "            continue\n",
    "        if this_image.tileData.framesPerTile < OUTPUT_N_FRAMES:\n",
    "            logger.warning(f\"Skipping image of id {idx} at {this_impath} do to insufficient framesPerTile ({this_image.tileData.framesPerTile} not {OUTPUT_N_FRAMES})\")\n",
    "            continue # skipping those without OUTPUT_N_FRAMES frames\n",
    "        this_ds[idx] = this_image\n",
    "    else:\n",
    "        logger.error(f\"Could not find image of id {idx} at {this_impath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ad5717",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"Found {len(this_ds)} images for dataset\")\n",
    "print(f\"Found {len(this_ds)} images for dataset\")\n",
    "if len(this_ds) < 1:\n",
    "    logger.error(f\"No valid images were found in {INPUT_DIREC}\")\n",
    "    raise Exception(f\"No valid images were found in {INPUT_DIREC}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22bd624",
   "metadata": {},
   "source": [
    "### Documenting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dacb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DS_NAME = f\"{datetime.now().strftime('%Y%m%d')}_{len(this_ds)}I_{DS_TYPE}_{INPUT_N_FRAMES}to{OUTPUT_N_FRAMES}F\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6748cacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_json = {\n",
    "    \"FLAME_Dataset\": {\n",
    "        \"name\": DS_NAME,\n",
    "        \"type\": DS_TYPE,\n",
    "        \"image_shapes\": [],\n",
    "        \"input\": {\n",
    "            \"n_frames\": INPUT_N_FRAMES,\n",
    "            \"pixel_mean\": None,\n",
    "            \"pixel_min\": None,\n",
    "            \"pixel_max\": None,\n",
    "            \"pixel_p1pct\": None,\n",
    "            \"pixel_1pct\": None,\n",
    "            \"pixel_5pct\": None,\n",
    "            \"pixel_95pct\": None,\n",
    "            \"pixel_99pct\": None,\n",
    "            \"pixel_99p9pct\": None,\n",
    "            \"pixel_std\": None,\n",
    "        },\n",
    "        \"output\": {\n",
    "            \"n_frames\": OUTPUT_N_FRAMES,\n",
    "            \"pixel_mean\": None,\n",
    "            \"pixel_min\": None,\n",
    "            \"pixel_max\": None,\n",
    "            \"pixel_p1pct\": None,\n",
    "            \"pixel_1pct\": None,\n",
    "            \"pixel_5pct\": None,\n",
    "            \"pixel_95pct\": None,\n",
    "            \"pixel_99pct\": None,\n",
    "            \"pixel_99p9pct\": None,\n",
    "            \"pixel_std\": None,\n",
    "        },\n",
    "        \"image_ids\": list(this_ds.keys()),\n",
    "        \"test_ids\": random.choices(list(this_ds.keys()), k=int(0.1*len(this_ds)))\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62383d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There are {len(dataset_json['FLAME_Dataset']['image_ids'])} images in the dataset\")\n",
    "logger.info(f\"There are {len(dataset_json['FLAME_Dataset']['image_ids'])} images in the dataset\")\n",
    "print(f\"There is a {len(dataset_json['FLAME_Dataset']['test_ids'])}-image testing subset\")\n",
    "logger.info(f\"There is a {len(dataset_json['FLAME_Dataset']['test_ids'])}-image testing subset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792d46c3",
   "metadata": {},
   "source": [
    "### Creating Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5615d393",
   "metadata": {},
   "outputs": [],
   "source": [
    "DS_OUTPUT_DIREC = os.path.join(OUTPUT_DIREC, DS_NAME)\n",
    "os.makedirs(DS_OUTPUT_DIREC, exist_ok=True)\n",
    "logger.info(f\"Created dataset output directory at {DS_OUTPUT_DIREC}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7d8b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIREC = os.path.join(DS_OUTPUT_DIREC, \"train\")\n",
    "TEST_DIREC = os.path.join(DS_OUTPUT_DIREC, \"test\")\n",
    "os.makedirs(TRAIN_DIREC, exist_ok=True)\n",
    "os.makedirs(TEST_DIREC, exist_ok=True)\n",
    "logger.info(f\"Created training data directory at {TRAIN_DIREC}\")\n",
    "logger.info(f\"Created testing data directory at {TEST_DIREC}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67306e47",
   "metadata": {},
   "source": [
    "##### Assert that all dtypes are the same\n",
    "\n",
    "This is important for the purpose of calculating statistics about the dataset. If all of the dtypes are the same, then the pixel-level intensity statistics can be calculated across the whole dataset, which is currently supported.\n",
    "\n",
    "If there are many different dtypes across the dataset, then sub-datasets will have to be created for each datatype, with pixel-level intensity statistics being calculated for each sub-dataset for normalization. Once each sub-dataset is normalized according to its own pixel intensity statistics, then they sub-datasets can be recombined into a larger dataset. *THIS IS NOT CURRENTLY SUPPORTED*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc604bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAME_Images = list(this_ds.values())\n",
    "adtype = FLAME_Images[0].imDType\n",
    "for this_fl_im in FLAME_Images:\n",
    "    assert this_fl_im.imDType == adtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3cabff",
   "metadata": {},
   "source": [
    "##### Create and save input an output images for low frame count and high frame count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fce6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_frames_paths = []\n",
    "output_frames_paths = []\n",
    "all_input_pixels = None\n",
    "all_output_pixels = None\n",
    "TEST_IDS = dataset_json['FLAME_Dataset']['test_ids']\n",
    "for idx, flame_im in tqdm(\n",
    "        this_ds.items(),\n",
    "        ascii=True,\n",
    "        unit=\"image\",\n",
    "        total=len(this_ds)\n",
    "    ):\n",
    "    flame_im.openImage() # load image data into memory first\n",
    "\n",
    "    # getting input frames by summing 0 to INPUT_N_FRAMES\n",
    "    input_frames_path = os.path.join(\n",
    "        TEST_DIREC if idx in TEST_IDS else TRAIN_DIREC, \n",
    "        f\"id{idx}_frames{INPUT_N_FRAMES}.tif\"\n",
    "    )\n",
    "    input_frames_paths.append(input_frames_path)\n",
    "    input_frames = flame_im.get_frames(0, INPUT_N_FRAMES)\n",
    "    logger.info(f\"Saving {input_frames_path}...\")\n",
    "    tiff.imwrite(input_frames_path, input_frames)\n",
    "\n",
    "    # adding shapes to dataset json if not present yet\n",
    "    if input_frames.shape not in dataset_json['FLAME_Dataset']['image_shapes']:\n",
    "        dataset_json['FLAME_Dataset']['image_shapes'].append(input_frames.shape)\n",
    "    \n",
    "    # getting output frames by summing 0 to OUTPUT_N_FRAMES\n",
    "    output_frames_path = os.path.join(\n",
    "        TEST_DIREC if idx in TEST_IDS else TRAIN_DIREC,\n",
    "        f\"id{idx}_frames{OUTPUT_N_FRAMES}.tif\"\n",
    "    )\n",
    "    output_frames_paths.append(output_frames_path)\n",
    "    output_frames = flame_im.get_frames(0, OUTPUT_N_FRAMES)\n",
    "    logger.info(f\"Saving {output_frames_path}...\")\n",
    "    tiff.imwrite(output_frames_path, output_frames)\n",
    "\n",
    "    # adding pixels in this image to large whole-dataset array\n",
    "    nchannels = len(flame_im.tileData.channelsSaved)\n",
    "    if all_input_pixels is None:\n",
    "        all_input_pixels = input_frames.reshape(nchannels, -1)\n",
    "        all_output_pixels = output_frames.reshape(nchannels, -1)\n",
    "    else:\n",
    "        all_input_pixels = np.concat([all_input_pixels, input_frames.reshape(nchannels, -1)], axis=-1)\n",
    "        all_output_pixels = np.concat([all_output_pixels, output_frames.reshape(nchannels, -1)], axis=-1)\n",
    "\n",
    "    flame_im.closeImage() # close image and force garbage collection for memory management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc54d353",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, arr in zip([\"input\", \"output\"], [all_input_pixels, all_output_pixels]):\n",
    "    dataset_json['FLAME_Dataset'][name]['pixel_p1pct'] = np.percentile(arr, 0.1, axis= 1).tolist()\n",
    "    dataset_json['FLAME_Dataset'][name]['pixel_1pct'] = np.percentile(arr, 1, axis = 1).tolist()\n",
    "    dataset_json['FLAME_Dataset'][name]['pixel_5pct'] = np.percentile(arr, 5, axis = 1).tolist()\n",
    "    dataset_json['FLAME_Dataset'][name]['pixel_95pct'] = np.percentile(arr, 95, axis = 1).tolist()\n",
    "    dataset_json['FLAME_Dataset'][name]['pixel_99pct'] = np.percentile(arr, 99, axis = 1).tolist()\n",
    "    dataset_json['FLAME_Dataset'][name]['pixel_99p9pct'] = np.percentile(arr, 99.9, axis = 1).tolist()\n",
    "    dataset_json['FLAME_Dataset'][name]['pixel_min'] = int(np.min(arr))\n",
    "    dataset_json['FLAME_Dataset'][name]['pixel_max'] = int(np.max(arr))\n",
    "    dataset_json['FLAME_Dataset'][name]['pixel_mean'] = float(np.mean(arr))\n",
    "    dataset_json['FLAME_Dataset'][name]['pixel_std'] = float(np.std(arr))\n",
    "\n",
    "del all_input_pixels\n",
    "del all_output_pixels\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb73968",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = os.path.join(DATASET_DIREC, f\"{DS_NAME}.json\")\n",
    "json.dump(dataset_json, open(json_path, \"w+\"))\n",
    "logger.info(f\"Saving dataset config JSON to {json_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb5bdf4",
   "metadata": {},
   "source": [
    "### Verification of processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d35300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "from matplotlib import pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ae4176",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(range(len(input_frames_paths)))\n",
    "random.shuffle(indices)\n",
    "choices = indices[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638f0aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (8, 4 * len(choices)))\n",
    "input_json, output_json = dataset_json['FLAME_Dataset']['input'], dataset_json['FLAME_Dataset']['output']\n",
    "for idx, choice in enumerate(choices):\n",
    "    left_ax = fig.add_subplot(len(choices), 2, 2 * idx + 1)\n",
    "    right_ax = fig.add_subplot(len(choices), 2, 2 * idx + 2)\n",
    "    \n",
    "    # Normalizing low frame image\n",
    "    low_frames = tiff.imread(input_frames_paths[choice]).transpose(1, 2, 0).astype(np.float64)\n",
    "    low_lower, low_upper = np.array(input_json['pixel_1pct']), np.array(input_json['pixel_99pct'])\n",
    "    low_frames = np.clip(low_frames, low_lower, low_upper)\n",
    "    low_frames = (low_frames - low_lower) / (low_upper - low_lower)\n",
    "    low_frames = low_frames.astype(np.float32)\n",
    "\n",
    "    # Normalizing high frame image\n",
    "    high_frames = tiff.imread(output_frames_paths[choice]).transpose(1, 2, 0).astype(np.float64)\n",
    "    high_lower, high_upper = np.array(output_json['pixel_1pct']), np.array(output_json['pixel_99pct'])\n",
    "    high_frames = np.clip(high_frames, high_lower, high_upper)\n",
    "    high_frames = (high_frames - high_lower) / (high_upper - high_lower)\n",
    "    high_frames = high_frames.astype(np.float32)\n",
    "\n",
    "    # Visualizing\n",
    "    left_ax.imshow(low_frames)\n",
    "    right_ax.imshow(high_frames)\n",
    "\n",
    "    imname = os.path.basename(input_frames_paths[choice])\n",
    "    im_id = int(imname.split(\"_\")[0].split(\"id\")[1])\n",
    "    im_path = IMAGE_INDEX.loc[IMAGE_INDEX['id'] == im_id, 'image'].iloc[0]\n",
    "    im_name = \"\\n\".join(im_path.split(os.path.sep)[-2:])\n",
    "    left_ax.set_ylabel(im_name)\n",
    "\n",
    "    if idx == 0:\n",
    "        left_ax.set_title(f\"{INPUT_N_FRAMES} frames\")\n",
    "        right_ax.set_title(f\"{OUTPUT_N_FRAMES} frames\")\n",
    "\n",
    "plt.savefig(os.path.join(DATASET_DIREC, f\"{DS_NAME}.png\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "care",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
