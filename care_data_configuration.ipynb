{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4812d33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-27 14:14:54.063810: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-27 14:14:54.128284: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748380494.150812 2680273 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748380494.156464 2680273 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1748380494.197602 2680273 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748380494.197633 2680273 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748380494.197635 2680273 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748380494.197636 2680273 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-27 14:14:54.209919: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import json\n",
    "from datetime import datetime\n",
    "import gc\n",
    "\n",
    "import tensorflow as tf\n",
    "from csbdeep.models import CARE\n",
    "from csbdeep.data import RawData, create_patches, no_background_patches\n",
    "from csbdeep.utils import plot_some\n",
    "from natsort import natsorted\n",
    "import tifffile as tiff\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from flame.utils import min_max_norm\n",
    "from flame import FLAMEImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b9bb316",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(tf.config.list_physical_devices(\"GPU\")) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a535c4",
   "metadata": {},
   "source": [
    "### WARNING: This Notebook may not work if processed dataset images are not YXC format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15653f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"20250527_112I_denoising_5to40F\" # processed dataset directory (created by 'create_care_dataset.ipynb')\n",
    "DATASET_DIREC = \"/mnt/d/code/Balu_CARE/datasets\"\n",
    "DATASET_JSON_PATH = os.path.join(DATASET_DIREC, f\"{DATASET_NAME}.json\")\n",
    "INPUT_DATA_DIREC = os.path.join(\"/mnt/d/data/processed/\", DATASET_NAME)\n",
    "assert os.path.isdir(INPUT_DATA_DIREC), f\"Directory not found: {INPUT_DATA_DIREC}\"\n",
    "TRAIN_DATA_DIREC = os.path.join(INPUT_DATA_DIREC, \"train\")\n",
    "assert os.path.isdir(TRAIN_DATA_DIREC), f\"Directory not found: {TRAIN_DATA_DIREC}\"\n",
    "FRAMES_LOW = 5\n",
    "FRAMES_GT = 40\n",
    "PATCH_SIZE = 128\n",
    "PATCH_MULTIPLE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f847bba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(\"main\")\n",
    "logging.basicConfig(\n",
    "    filename=f\"{datetime.now().strftime('%Y%m%d-%H%M%S')}_logger.log\",\n",
    "    encoding=\"utf-8\",\n",
    "    level=logging.DEBUG\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a32cb307",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"Using {TRAIN_DATA_DIREC} to construct the CARE training data .npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4b1de6",
   "metadata": {},
   "source": [
    "### Getting paths of Low Frame and Ground Truth Frame Accumulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c494eb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_paths = []\n",
    "GT_paths = []\n",
    "for root, dirs, files in os.walk(TRAIN_DATA_DIREC):\n",
    "    for f in files:\n",
    "        if f\"frames{FRAMES_LOW}\" in f:\n",
    "            low_paths.append(os.path.join(root, f))\n",
    "        elif f\"frames{FRAMES_GT}\" in f:\n",
    "            GT_paths.append(os.path.join(root, f))\n",
    "\n",
    "low_paths = natsorted(low_paths)\n",
    "GT_paths = natsorted(GT_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5edb61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 102 low- and high-frame accumulation images for this dataset\n"
     ]
    }
   ],
   "source": [
    "print(f\"Found {len(low_paths)} low- and high-frame accumulation images for this dataset\")\n",
    "logger.info(f\"Found {len(low_paths)} low- and high-frame accumulation images for this dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a71e30fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f1, f2 in zip(low_paths, GT_paths):\n",
    "    id1 = os.path.basename(f1).split('_')[0]\n",
    "    id2 = os.path.basename(f2).split('_')[0]\n",
    "    assert id1 == id2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0142195d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_config = json.load(open(DATASET_JSON_PATH, 'r'))\n",
    "input_config = ds_config['FLAME_Dataset']['input']\n",
    "output_config = ds_config['FLAME_Dataset']['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88e02d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1pct, input_99pct = np.array(input_config['pixel_1pct']), np.array(input_config['pixel_99pct'])\n",
    "output_1pct, output_99pct = np.array(output_config['pixel_1pct']), np.array(output_config['pixel_99pct'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49aae07d",
   "metadata": {},
   "source": [
    "### Min-max norm of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87b5566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get largest shape\n",
    "largest_x = 0\n",
    "largest_y = 0\n",
    "for shape in ds_config['FLAME_Dataset']['image_shapes']:\n",
    "    this_y = shape[0]\n",
    "    this_x = shape[1]\n",
    "    if this_x > largest_x: largest_x = this_x\n",
    "    if this_y > largest_y: largest_y = this_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6f38b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "low = []\n",
    "GT = []\n",
    "# Assumes that all image shapes are XYC format\n",
    "for low_path, GT_path in tqdm(\n",
    "        zip(low_paths, GT_paths),\n",
    "        ascii=True,\n",
    "        unit=\"image\",\n",
    "        total=len(low_paths)\n",
    "    ):\n",
    "\n",
    "    # default tiff.imread behavior is to read CYX (even if the tif is not written that way), so transpose to YXC\n",
    "    # also convert to float 32 to allow for full range during min-max normalization\n",
    "    this_low = tiff.imread(low_path).transpose(1,2,0).astype(np.float32)\n",
    "    this_GT = tiff.imread(GT_path).transpose(1,2,0).astype(np.float32)\n",
    "\n",
    "    imshape = this_low.shape\n",
    "    this_y, this_x, this_c = imshape[0], imshape[1], imshape[2]\n",
    "\n",
    "    # if the shape of the current input image is not correct, frame it insize the largest x-y possible\n",
    "    if largest_x != this_x or largest_y != this_y:\n",
    "        low_zeroes = np.zeros(shape=(largest_y, largest_x, this_c))\n",
    "        GT_zeroes = low_zeroes.copy()\n",
    "        low_zeroes[:this_y, :this_x, :] = this_low\n",
    "        GT_zeroes[:this_y, :this_x, :] = this_GT\n",
    "        # delete what is currently in this_low and this_GT, since it will be overwritten\n",
    "        del this_low\n",
    "        del this_GT\n",
    "        this_low = low_zeroes\n",
    "        this_GT = GT_zeroes\n",
    "        \n",
    "    low.append(np.clip(min_max_norm(this_low, input_1pct, input_99pct), 0, 1))\n",
    "    GT.append(np.clip(min_max_norm(this_GT, output_1pct, output_99pct), 0, 1))\n",
    "    # delete lagging pointers and collect garbage for memory management\n",
    "    del this_low\n",
    "    del this_GT\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8aa8dc",
   "metadata": {},
   "source": [
    "### Removing channel dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acec201d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all input arrays must have the same shape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m low \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      2\u001b[0m GT \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack(GT, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/care/lib/python3.12/site-packages/numpy/_core/shape_base.py:457\u001b[0m, in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out, dtype, casting)\u001b[0m\n\u001b[1;32m    455\u001b[0m shapes \u001b[38;5;241m=\u001b[39m {arr\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays}\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shapes) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall input arrays must have the same shape\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    459\u001b[0m result_ndim \u001b[38;5;241m=\u001b[39m arrays[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    460\u001b[0m axis \u001b[38;5;241m=\u001b[39m normalize_axis_index(axis, result_ndim)\n",
      "\u001b[0;31mValueError\u001b[0m: all input arrays must have the same shape"
     ]
    }
   ],
   "source": [
    "low = np.stack(low, axis=-1).astype(np.float32).transpose(2, 3, 0, 1)\n",
    "GT = np.stack(GT, axis=-1).astype(np.float32).transpose(2, 3, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f05cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Frame{FRAMES_LOW}: {low.shape}, {low.dtype}\")\n",
    "print(f\"Frame{FRAMES_GT}: {GT.shape}, {GT.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755fffbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_x_S = np.cumprod(np.array(low.shape[0:2]))[1]\n",
    "Y = low.shape[2]\n",
    "X = low.shape[3]\n",
    "print(C_x_S)\n",
    "low_test = np.reshape(low, (C_x_S,Y,X))\n",
    "GT_test = np.reshape(GT, (C_x_S,Y,X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c043c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Frame{FRAMES_LOW}: {low_test.shape}, {low_test.dtype}\")\n",
    "print(f\"Frame{FRAMES_GT}: {GT_test.shape}, {GT_test.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567d2dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = RawData.from_arrays(\n",
    "    X=low,\n",
    "    Y=GT,\n",
    "    axes=\"SCYX\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3eda637",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_patch_per_im = low.shape[-1] // PATCH_SIZE * 2\n",
    "\n",
    "X, Y, XY_axes = create_patches(\n",
    "    raw_data=raw_data,\n",
    "    patch_size=(low.shape[1], PATCH_SIZE, PATCH_SIZE),\n",
    "    patch_axes=\"CYX\",\n",
    "    patch_filter=no_background_patches(0),\n",
    "    n_patches_per_image=low.shape[-1] // PATCH_SIZE * PATCH_MULTIPLE,\n",
    "    normalization=None,\n",
    "    save_file=os.path.join(INPUT_DATA_DIREC, f\"{DATASET_NAME}_patch{PATCH_SIZE}_{n_patch_per_im}PpI.npz\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac136319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from: https://nbviewer.org/url/csbdeep.bioimagecomputing.com/examples/denoising2D/1_datagen.ipynb\n",
    "for i in range(2):\n",
    "    plt.figure(figsize=(16,4))\n",
    "    sl = slice(8*i, 8*(i+1)), 0\n",
    "    plot_some(\n",
    "        X[sl],\n",
    "        Y[sl],\n",
    "        title_list=[np.arange(sl[0].start,sl[0].stop)],\n",
    "    )\n",
    "    plt.show()\n",
    "None;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "care",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
